import streamlit as st
import PyPDF2
import openai
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pdfminer.high_level import extract_text
import re
import os
import subprocess
from io import BytesIO
import os

import streamlit as st

# API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = st.secrets.get("general", {}).get("API_KEY", None)

if api_key is None:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets.toml ë˜ëŠ” Streamlit Cloud Secretsì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
else:
    st.success("API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")




def extract_and_clean_text(file):
    criteria = extract_text(file).strip()
    return criteria.strip()

def extract_text_from_pdf(file):
    structured_sections = ""
    reader = PyPDF2.PdfReader(file)
    for page in reader.pages:
        structured_sections += page.extract_text() + "\n"
    return structured_sections

def parse_scores(result_text, question_count):
    """Parse scores based on the number of questions"""
    scores = {}
    
    if question_count == 1:
        # Single question format
        total_match = re.search(r"ì´ì \s*:\s*(\d+)", result_text)
        if total_match:
            scores["ì´ì "] = int(total_match.group(1))
    else:
        # Multiple questions format
        question_scores = re.finditer(r"ë¬¸ì œ\s*(\d+-\d+)\s*ì´ì \s*:\s*(\d+)", result_text)
        for match in question_scores:
            question_num = match.group(1)
            score = int(match.group(2))
            scores[f"ë¬¸ì œ{question_num}"] = score
    
    return scores



def get_grading_prompt(question_count):
    """Return appropriate prompts based on number of questions"""
    system_prompt = """
    ë‹¹ì‹ ì€ ë²•í•™ ì„œìˆ í˜• ë‹µì•ˆì„ ì±„ì í•˜ëŠ” ì—„ê²©í•˜ê³  ê³µì •í•œ ì±„ì ê´€ì…ë‹ˆë‹¤.
    ëª¨ë“  ì±„ì  ê¸°ì¤€ì„ ì„¸ë°€í•˜ê²Œ ê²€í† í•˜ê³ , ì±„ì  ê¸°ì¤€ì— ë”°ë¥¸ ì¶©ì¡± ì—¬ë¶€ë¥¼ ëª…í™•í•˜ê²Œ íŒë‹¨í•˜ì„¸ìš”.
    - ë¬¸ì œê°€ ëª¨í˜¸í•  ê²½ìš° í•­ìƒ ë³´ìˆ˜ì ìœ¼ë¡œ íŒë‹¨í•˜ê³ , í•™ìƒì´ ëª…í™•íˆ ì„¤ëª…í•˜ì§€ ëª»í•œ ë¶€ë¶„ì€ ê°ì í•˜ì„¸ìš”.
    - ì±„ì ê¸°ì¤€ì— ë‚˜ì˜¨ 'ì œnì¡°'ê°€ ëª…ì‹œ ë˜ì–´ìˆì§€ì•Šìœ¼ë©´ ê°ì í•˜ì„¸ìš”.
    - ì±„ì  ê¸°ì¤€ì„ í•˜ë‚˜ì”© ë‹¤ ë‚˜ëˆ ì„œ ì±„ì í•´ì£¼ì„¸ìš”.
    - ì ìˆ˜ ë¶€ì—¬ ì‹œ ê·¼ê±°ë¥¼ ëª…í™•í•˜ê²Œ í™•ì¸í•´ì£¼ì„¸ìš”.
    """

    if question_count == 1:
        user_prompt_template = """
        ì±„ì  ê¸°ì¤€:
        {guideline}

        í•™ìƒ ë‹µì•ˆ:
        {answer}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
        1. ì±„ì  ê¸°ì¤€ì— ë”°ë¼ í•™ìƒ ë‹µì•ˆì´ ì–¼ë§ˆë‚˜ ì¶©ì¡±ë˜ì—ˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
        2. ì±„ì ê¸°ì¤€ì— ë‚˜ì˜¨ 'ì œnì¡°'ê°€ ëª…ì‹œ ë˜ì–´ìˆì§€ì•Šìœ¼ë©´ ê°ì í•˜ì„¸ìš”.
        3. ì±„ì  ê¸°ì¤€ì„ í•˜ë‚˜ì”© ë‹¤ ë‚˜ëˆ ì„œ ì±„ì í•´ì£¼ì„¸ìš”.
        4. ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³  ê·¼ê±°ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        5. ì ìˆ˜ëŠ” ì •ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ì£¼ì„¸ìš”.

        ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
        ë¬¸ì œ 1
        - ê·¼ê±° :
        - ë¬¸ì œ 1 ì´ì  : [ìˆ«ì]
        """
    else:
        user_prompt_template = """
        ì±„ì  ê¸°ì¤€:
        {guideline}

        í•™ìƒ ë‹µì•ˆ:
        {answer}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
        1. ê° ë¬¸ì œ(ì˜ˆ: 2-1, 2-2)ë³„ë¡œ ë‚˜ëˆ ì„œ ì±„ì í•´ì£¼ì„¸ìš”.
        2. ê° ì±„ì  ê¸°ì¤€ì— ë”°ë¼ í•™ìƒ ë‹µì•ˆì´ ì–¼ë§ˆë‚˜ ì¶©ì¡±ë˜ì—ˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
        3. ì±„ì ê¸°ì¤€ì— ë‚˜ì˜¨ 'ì œnì¡°'ê°€ ëª…ì‹œ ë˜ì–´ìˆì§€ì•Šìœ¼ë©´ ê°ì í•˜ì„¸ìš”.
        4. ì±„ì  ê¸°ì¤€ì„ í•˜ë‚˜ì”© ë‹¤ ë‚˜ëˆ ì„œ ì±„ì í•´ì£¼ì„¸ìš”.
        5. ê° ë¬¸ì œë³„ ì ìˆ˜ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”.
        6. ì ìˆ˜ëŠ” ì •ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ì£¼ì„¸ìš”.

        ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:
        ë¬¸ì œ 2-1
        - ê·¼ê±° :
        - ë¬¸ì œ 2-1 ì´ì  : [ìˆ«ì]

        ë¬¸ì œ 2-2
        - ê·¼ê±° :
        - ë¬¸ì œ 2-2 ì´ì  : [ìˆ«ì]
        """
    
    return system_prompt, user_prompt_template

def grade_with_openai(guideline, answer, question_count):
    """Grade answers using OpenAI API with appropriate prompts"""
    system_prompt, user_prompt_template = get_grading_prompt(question_count)

    # Format user prompt
    user_prompt = user_prompt_template.format(
        guideline=guideline,
        answer=answer
    )

    # API call
    response = openai.ChatCompletion.create(
        model="gpt-4o",  # Using gpt-4o as requested
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
            ],
            temperature=0,
    )

    # Return the response content
    return response["choices"][0]["message"]["content"].strip()

def clear_uploaded_files():
    """Clear all uploaded files and reset the session state."""
    st.session_state.results = []
    st.session_state.graph_data = {}
    if 'criteria_file' in st.session_state:
        del st.session_state['criteria_file']
    if 'answer_files' in st.session_state:
        del st.session_state['answer_files']

    st.write('<meta http-equiv="refresh" content="0; url=/" />', unsafe_allow_html=True)

def merge_uploaded_csvs(uploaded_files):
    """CSV íŒŒì¼ì„ í•™ìƒë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•˜ê³  ì´ì ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    dataframes = [pd.read_csv(file) for file in uploaded_files]

    # í•™ìƒë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
    merged_df = dataframes[0]
    for df in dataframes[1:]:
        merged_df = merged_df.merge(df, on="í•™ìƒë²ˆí˜¸", how="outer")

    # NaN ê°’ì„ 0ìœ¼ë¡œ ë³€í™˜ í›„ ì´ì  ê³„ì‚°
    score_columns = [col for col in merged_df.columns if col.startswith("ë¬¸ì œ")]
    merged_df["ì´ì "] = merged_df[score_columns].fillna(0).sum(axis=1)

    # ì´ì ì„ ë§¨ ì™¼ìª½ìœ¼ë¡œ ì´ë™
    column_order = ["ì´ì ", "í•™ìƒë²ˆí˜¸"] + score_columns
    merged_df = merged_df[column_order]

    return merged_df

def convert_df_to_csv(df):
    """DataFrameì„ CSV íŒŒì¼ë¡œ ë³€í™˜"""
    output = BytesIO()
    df.to_csv(output, index=False, encoding="utf-8-sig")
    return output.getvalue()

def main():
    st.set_page_config(
        initial_sidebar_state="expanded",
        layout="wide",
        page_icon="âš–ï¸",
        page_title="ë²•ë¥  ì±„ì  í”„ë¡œê·¸ë¨ | FELT"
    )

    col1, col2 = st.columns([3, 2])

    with col1:
        st.header("âš–ï¸ ë²•ë¥  ì±„ì  í”„ë¡œê·¸ë¨ | FELT")

        st.sidebar.title("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")

        if st.button("ğŸ—‘ï¸ ìƒˆë¡œìš´ ë¬¸ì œ ì±„ì ", type="secondary"):
            clear_uploaded_files()
        st.text("ìƒˆë¡œìš´ ì±„ì ì´ ì§„í–‰ë ë•Œ ê¼­ í´ë¦­í•´ì£¼ì„¸ìš”!")

        question_count = st.sidebar.radio(
            "ë¬¸ì œ ê°œìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            options=[1, 2],
            format_func=lambda x: f"{x}ë¬¸ì œ",
            index=0
        )

        criteria_file = st.sidebar.file_uploader("ì±„ì  ê¸°ì¤€ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"], key="criteria_file")
        answer_files = st.sidebar.file_uploader("í•™ìƒ ë‹µì•ˆ PDF íŒŒì¼ì„ ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"], accept_multiple_files=True, key="answer_files")

        if "results" not in st.session_state:
            st.session_state.results = []
            st.session_state.graph_data = {}

        if st.sidebar.button("âœ… ì±„ì  ì‹œì‘"):
            st.session_state.results = []
            st.session_state.graph_data = {}

            if criteria_file is None:
                st.sidebar.error("ì±„ì  ê¸°ì¤€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return

            if not answer_files:
                st.sidebar.error("í•™ìƒ ë‹µì•ˆ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return

            with st.spinner("ì±„ì  ê¸°ì¤€ì„ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
                criteria_text = extract_and_clean_text(criteria_file)

            results = []
            graph_data = {}
            question_scores = {}

            for i, file in enumerate(answer_files):
                with st.spinner(f"í•™ìƒ ë‹µì•ˆ {i + 1} ì±„ì  ì¤‘ì…ë‹ˆë‹¤..."):
                    answer_text = extract_text_from_pdf(file)
                    result = grade_with_openai(criteria_text, answer_text, question_count)
                    results.append((file.name, result))

                    # Parse scores for graph data
                    scores = parse_scores(result, question_count)
                    for question, score in scores.items():
                        if question not in graph_data:
                            graph_data[question] = []
                        graph_data[question].append(score)

                        if question not in question_scores:
                            question_scores[question] = []
                        question_scores[question].append(score)

            st.session_state.results = results
            st.session_state.graph_data = graph_data

            st.subheader("ì±„ì  ê²°ê³¼")
            csv_data = []

            for file_name, result in results:
                st.write(f"**í•™ìƒ ë‹µì•ˆ íŒŒì¼ëª…: {file_name}**")
                st.text(result)
                st.write("---")

                file_name = file_name.replace('.pdf', '')
                scores = parse_scores(result, question_count)
                row_data = {"í•™ìƒë²ˆí˜¸": file_name}
                row_data.update(scores)
                csv_data.append(row_data)

            if csv_data:
                csv_df = pd.DataFrame(csv_data)
                if question_count == 2 and "ì´ì " in csv_df.columns:
                    csv_df = csv_df.drop(columns=["ì´ì "])
                csv_file = "grading_results.csv"
                csv_df.to_csv(csv_file, index=False, encoding="utf-8-sig")
                st.sidebar.download_button(
                    label="ğŸ“¥ ì±„ì  ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=open(csv_file, "rb"),
                    file_name="grading_results.csv",
                    mime="text/csv"
                )
                
        st.sidebar.subheader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ ë° ë³‘í•©")
        uploaded_csvs = st.sidebar.file_uploader("ì±„ì  ê²°ê³¼ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"], accept_multiple_files=True)

        if uploaded_csvs:
            merged_df = merge_uploaded_csvs(uploaded_csvs)
            st.subheader("ğŸ“Š ë³‘í•©ëœ ì±„ì  ê²°ê³¼")
            st.write(merged_df)

            st.sidebar.download_button(
                label="ğŸ“¥ ë³‘í•©ëœ ì±„ì  ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=convert_df_to_csv(merged_df),
                file_name="merged_grading_results.csv",
                mime="text/csv",
            )
        else:
            st.sidebar.info("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ í•™ìƒë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    with col2:
        st.header("ğŸ“Š ì±„ì  ê²°ê³¼")

        if st.session_state.results:
            graph_data = st.session_state.graph_data

            for question, scores in graph_data.items():
                st.subheader(f"{question} ë¶„í¬")

                fig, ax = plt.subplots(figsize=(8, 6))
                score_counts = pd.Series(scores).value_counts().sort_index()
                ax.bar(score_counts.index, score_counts.values,  # ìˆ˜ì •: indexë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    color="skyblue", edgecolor="black")
                ax.set_xlabel("Score")
                ax.set_ylabel("Number of students")
                ax.set_title(f"Distribution")
                ax.grid(True, linestyle="--", alpha=0.6)
                st.pyplot(fig)

                # Display statistics for each question
                st.write(f"**{question} í†µê³„ ì •ë³´:**")
                st.write(f"- ìµœê³  ì ìˆ˜: {max(scores)}")
                st.write(f"- ìµœì € ì ìˆ˜: {min(scores)}")
                st.write(f"- í‰ê·  ì ìˆ˜: {np.mean(scores):.2f}")

        else:
            st.info("ì±„ì  ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì±„ì ì„ ì‹œì‘í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
